=======================
Perform Bulk Operations
=======================

.. default-domain:: mongodb

.. note::
   If you specify a callback method, ``bulkWrite()`` returns nothing. If you
   do not specify one, this method returns a
   :mdn:`Promise <Web/JavaScript/Reference/Global_Objects/Promise>` that
   resolves to the result object when it completes. For more information on
   the result object type, see the
   :node-api:`API documentation <BulkWriteResult.html>`.

The ``bulkWrite()`` method performs batch write operations against a
*single* collection. This method reduces the number of network roundtrips from
your application to the server which therefore increases the throughput and
performance. Since you only receive the success status after the batch
write returns, we recommend you use this if that meets the requirements
of your use case.

You can specify one or more of the following write operations in
``bulkWrite()``:

- ``insertOne``
- ``updateOne``
- ``updateMany``
- ``deleteOne``
- ``deleteMany``
- ``replaceOne``

``bulkWrite()`` accepts the following parameters:

- ``operations``: specifies the bulk operations to
  perform. Pass each operation to ``bulkWrite()`` as an object in
  an array. For examples that show the syntax for each write operation, see
  the :node-api:`bulkWrite API documentation <Collection.html#bulkWrite>`.

- ``options``: *optional* settings that affect the execution
  of the operation, such as whether the write operations should execute in
  sequential order and the write concern.

  By default, MongoDB executes bulk write operations one-by-one in the
  specified order (i.e. serially). During an ordered bulk write, if
  an error occurs during the processing of an operation, MongoDB returns
  without processing the remaining operations in the list. In contrast,
  when ``ordered`` is ``false``, MongoDB continues to process remaining
  write operations in the list. Unordered operations are theoretically faster
  since MongoDB can execute them in parallel, but should only be used if
  the writes do not depend on order.

If you create an index with a :manual:`unique constraint
</core/index-unique>`, you might encounter a duplicate key write error
during an operation. The following example shows a duplicate key error
encountered when two of the users in the inserted sample dataset had the
same email address.

.. code-block:: sh

   Error during bulkWrite, BulkWriteError: E11000 duplicate key error collection: ...

Similarly, if you attempt to perform a bulk write against a collection
that uses :manual:`schema validation </core/schema-validation>`, you may
encounter warnings or errors related to the formatting of inserted or
modified documents.

Example
-------

The following code sample performs a bulk write operation on the
``theaters`` collection in the ``sample_mflix`` database. The example call
to ``bulkWrite()`` includes examples of ``insertOne``, ``updateMany``, and
``deleteOne`` write operations:

.. include:: /includes/connect-guide-note.rst

.. literalinclude:: /code-snippets/usage-examples/bulkWrite.js
   :language: javascript

When you run the code sample, your output should resemble the following:

.. code-block:: javascript

   BulkWriteResult {
     result: {
       ok: 1,
       writeErrors: [],
       writeConcernErrors: [],
       insertedIds: [ [Object], [Object] ],
       nInserted: 2,
       nUpserted: 0,
       nMatched: 1,
       nModified: 1,
       nRemoved: 0,
       upserted: [],
       lastOp: { ts: [Timestamp], t: 17 }
     },
     insertedCount: 2,
     matchedCount: 1,
     modifiedCount: 1,
     deletedCount: 0,
     upsertedCount: 0,
     upsertedIds: {},
     insertedIds: { '0': 5ec4..., '1': 5ec4... },
     n: 2
   }

Refer to the server manual documentation on
:manual:`bulkWrite() <reference/method/db.collection.bulkWrite>` for more
information on how to format each type of write operation.

